console.log("üîÑ IMPORTING CHEERIO (NO BROWSER NEEDED)...");
import * as cheerio from 'cheerio';
import fetch from 'node-fetch';
console.log("‚úÖ CHEERIO AND FETCH IMPORTED SUCCESSFULLY");
console.log("üîÑ IMPORTING SAVE SCRAPED DATA...");
import saveScrapedData from '../scraper/saveScrapedData.js';
console.log("‚úÖ SAVE SCRAPED DATA IMPORTED SUCCESSFULLY");

// Configuration constants
const CONFIG = {
    RETRY_ATTEMPTS: 3,
    RETRY_DELAY: 2000, // 2 seconds
    PAGE_TIMEOUT: 30000, // 30 seconds
    SCRAPE_TIMEOUT: 60000, // 1 minute total
};

console.log("‚úÖ CONFIG OBJECT CREATED");

// Validation functions
const validateData = {
    phone: (phone) => {
        return phone && phone.match(/[\d\s+\-()]+/);
    },
    email: (email) => {
        return email && email.match(/^[^\s@]+@[^\s@]+\.[^\s@]+$/);
    },
    services: (services) => {
        return Array.isArray(services) && services.length > 0;
    }
};

console.log("‚úÖ VALIDATION FUNCTIONS CREATED");

// Helper function for delay
const delay = ms => new Promise(resolve => setTimeout(resolve, ms));

// Helper function to retry failed operations
async function withRetry(operation, name, maxAttempts = CONFIG.RETRY_ATTEMPTS) {
    console.log(`üîÑ STARTING RETRY OPERATION: ${name}`);
    for (let attempt = 1; attempt <= maxAttempts; attempt++) {
        try {
            console.log(`üîÑ ATTEMPT ${attempt}/${maxAttempts} FOR: ${name}`);
            const result = await operation();
            console.log(`‚úÖ SUCCESS ON ATTEMPT ${attempt} FOR: ${name}`);
            return result;
        } catch (error) {
            console.log(`‚ùå ATTEMPT ${attempt} FAILED FOR: ${name}`, error.message);
            if (attempt === maxAttempts) {
                console.log(`üö® ALL ATTEMPTS FAILED FOR: ${name}`);
                throw error;
            }
            console.log(`‚ö†Ô∏è Attempt ${attempt} failed for ${name}. Retrying in ${CONFIG.RETRY_DELAY/1000}s...`);
            await delay(CONFIG.RETRY_DELAY);
        }
    }
}

console.log("‚úÖ HELPER FUNCTIONS CREATED");

const scrapeBusinessData = async (business) => {
    console.log("üöÄ STARTING SCRAPE BUSINESS DATA FUNCTION");
    console.log("üìã BUSINESS DATA:", JSON.stringify(business, null, 2));
    
    const startTime = Date.now();
    console.log('=== Cheerio Scraping (No Browser) ===');
    console.log('NODE_ENV:', process.env.NODE_ENV);
    console.log('üìä MEMORY BEFORE SCRAPING:', process.memoryUsage());
    
    try {
        console.log('üîÑ MAKING HTTP REQUEST TO WEBSITE...');
        console.log('üîÑ TARGET URL:', business.websiteUrl);
        
        // Fetch the webpage with timeout
        const response = await fetch(business.websiteUrl, {
            timeout: CONFIG.PAGE_TIMEOUT,
            headers: {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
        });
        
        if (!response.ok) {
            throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }
        
        console.log('‚úÖ HTTP REQUEST SUCCESSFUL');
        console.log('üìä Response status:', response.status);
        
        const html = await response.text();
        console.log('‚úÖ HTML CONTENT RECEIVED');
        console.log('üìä HTML length:', html.length);
        
        // Parse HTML with Cheerio
        console.log('üîÑ PARSING HTML WITH CHEERIO...');
        const $ = cheerio.load(html);
        console.log('‚úÖ HTML PARSED SUCCESSFULLY');
        
        // 1. Scrape Services
        console.log('üîÑ SCRAPING SERVICES...');
        const serviceSelector = business.selectors?.serviceSelector || 'h1, h2, h3, .service, .treatment';
        console.log('üîÑ SERVICE SELECTOR:', serviceSelector);
        
        const rawServices = [];
        $(serviceSelector).each((i, el) => {
            const text = $(el).text().trim();
            if (text && text.length > 3) {
                rawServices.push(text);
            }
        });
        
        console.log('‚úÖ RAW SERVICES SCRAPED:', rawServices);

        const services = rawServices.filter(text =>
            text.length > 3 &&
            !text.includes("Dr") &&
            !text.match(/Doctor|Meet|Our Team|Reviews|Testimonials|News|About|Specialist|Physician|Surgeon|Contact/i)
        ).slice(0, 10); // Limit to 10 services
        
        console.log('‚úÖ FILTERED SERVICES:', services);

        // 2. Scrape Contact Details
        console.log('üîÑ SCRAPING CONTACT DETAILS...');
        
        // Phone
        let phone = "Not found";
        const phoneSelectors = [
            business.selectors?.contactSelector?.phone,
            'a[href^="tel:"]',
            '.phone',
            '.contact-phone',
            '[class*="phone"]',
            '[id*="phone"]'
        ].filter(Boolean);
        
        for (const selector of phoneSelectors) {
            const phoneEl = $(selector).first();
            if (phoneEl.length) {
                phone = phoneEl.text().trim() || phoneEl.attr('href')?.replace('tel:', '') || phone;
                if (phone !== "Not found") break;
            }
        }
        
        // Email
        let email = "Not found";
        const emailSelectors = [
            business.selectors?.contactSelector?.email,
            'a[href^="mailto:"]',
            '.email',
            '.contact-email',
            '[class*="email"]',
            '[id*="email"]'
        ].filter(Boolean);
        
        for (const selector of emailSelectors) {
            const emailEl = $(selector).first();
            if (emailEl.length) {
                email = emailEl.text().trim() || emailEl.attr('href')?.replace('mailto:', '') || email;
                if (email !== "Not found") break;
            }
        }
        
        const contactDetails = { phone, email };
        console.log('‚úÖ CONTACT DETAILS SCRAPED:', contactDetails);

        // 3. Scrape FAQs (try FAQ page)
        let faqs = [];
        console.log('üîÑ ATTEMPTING TO SCRAPE FAQS...');
        try {
            const faqUrl = `${business.websiteUrl}/faq`;
            console.log('üîÑ TRYING FAQ PAGE:', faqUrl);
            
            const faqResponse = await fetch(faqUrl, {
                timeout: CONFIG.PAGE_TIMEOUT,
                headers: {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
            });
            
            if (faqResponse.ok) {
                const faqHtml = await faqResponse.text();
                const $faq = cheerio.load(faqHtml);
                
                if (business.selectors?.faqsSelector?.question && business.selectors?.faqsSelector?.answer) {
                    const questions = [];
                    const answers = [];
                    
                    $faq(business.selectors.faqsSelector.question).each((i, el) => {
                        questions.push($faq(el).text().trim());
                    });
                    
                    $faq(business.selectors.faqsSelector.answer).each((i, el) => {
                        answers.push($faq(el).text().trim());
                    });
                    
                    faqs = questions.map((q, i) => ({
                        question: q,
                        answer: answers[i] || "No answer found"
                    })).slice(0, 5); // Limit to 5 FAQs
                }
                console.log('‚úÖ FAQS SCRAPED:', faqs);
            } else {
                console.log('‚ö†Ô∏è FAQ page not accessible');
            }
        } catch (faqError) {
            console.log("‚ö†Ô∏è Could not scrape FAQs:", faqError.message);
        }

        // Save all scraped data
        console.log('üîÑ SAVING SCRAPED DATA...');
        const scrapedData = { services, contactDetails, faqs };
        console.log('üìä FINAL SCRAPED DATA:', JSON.stringify(scrapedData, null, 2));
        console.log('üìä MEMORY AFTER SCRAPING:', process.memoryUsage());
        
        await saveScrapedData(business.businessId, scrapedData);
        console.log('‚úÖ SCRAPED DATA SAVED SUCCESSFULLY');

        const duration = (Date.now() - startTime) / 1000;
        console.log(`üéâ SCRAPING COMPLETED SUCCESSFULLY IN ${duration} SECONDS`);

    } catch (error) {
        console.error('üö® CHEERIO SCRAPING ERROR:', error.message);
        console.error('üö® SCRAPING ERROR STACK:', error.stack);
        throw error;
    }
};

console.log("‚úÖ SCRAPE BUSINESS DATA FUNCTION DEFINED");

export default scrapeBusinessData;
